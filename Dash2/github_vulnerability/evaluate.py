import sys; sys.path.extend(['../../'])
import cPickle as pickle


def count_true_positives(sim, gt, pop_threshold=0):
    number_of_true_positives = 0

    for repo_id in sim.iterkeys():
        if repo_id in gt:
            if sim[repo_id] >= pop_threshold:
                number_of_true_positives += 1

    return number_of_true_positives


def count_false_positives(sim, gt, pop_threshold=0):
    number_of_false_positives = 0

    for repo_id in sim.iterkeys():
        if repo_id not in gt:
            if sim[repo_id] >= pop_threshold:
                number_of_false_positives += 1

    return number_of_false_positives


def count_elements(data, pop_threshold=0):
    number_of_sleceted_elements = 0

    for pop in data.itervalues():
        if pop >= pop_threshold:
            number_of_sleceted_elements += 1

    return number_of_sleceted_elements


def count_fp_reduction(sim, gt, training, pop_threshold=0):
    fp_reduction_counter = 0

    for repo_id in training.iterkeys():
        if training[repo_id] >= pop_threshold and repo_id not in gt and repo_id not in sim:
                fp_reduction_counter += 1

    return fp_reduction_counter


def count_tp_reduction(sim, gt, training, pop_threshold=0):
    tp_reduction_counter = 0

    for repo_id in training.iterkeys():
        if training[repo_id] >= pop_threshold and repo_id in gt and repo_id not in sim:
            tp_reduction_counter += 1

    return tp_reduction_counter


def count_fp_extension(sim, gt, training, pop_threshold=0):
    fp_extension_counter = 0

    for repo_id in sim.iterkeys():
        if sim[repo_id] >= pop_threshold and repo_id not in gt and repo_id not in training:
            fp_extension_counter += 1

    return fp_extension_counter


def count_tp_extension(sim, gt, training, pop_threshold=0):
    tp_extension_counter = 0

    for repo_id in sim.iterkeys():
        if sim[repo_id] >= pop_threshold and repo_id not in gt and repo_id not in training:
            tp_extension_counter += 1

    return tp_extension_counter


def evaluate_predictions(sim, gt, training, output_file_name=None, total_number_of_repos = 3245042):
    print "pop_threshold, TP, FP, FN, TN, total, precision, recall, sensitivity_tpr, specificity_tnr, fpr, fp_reduction, tp_reduction, fp_extension, tp_extension"

    evaluation_res = {} # [popularity_threshold][metric_name]

    for sim_index in range(len(sim)):
        evaluation_res[sim_index] = {}
        for pop_threshold in range(0, 11):
            TP = count_true_positives(sim[sim_index], gt, pop_threshold)
            FP = count_false_positives(sim[sim_index], gt, pop_threshold)

            number_of_selected_repos = count_elements(sim[sim_index], pop_threshold)
            number_of_relevant_repos = count_elements(gt, pop_threshold)

            FN = number_of_relevant_repos - TP
            TN = total_number_of_repos - FP

            precision = float(TP) / float(number_of_selected_repos) if number_of_selected_repos != 0 else "n/a"
            recall = float(TP) / float(number_of_relevant_repos) if number_of_relevant_repos != 0 else "n/a"

            sensitivity = float(TP) / float(number_of_relevant_repos) if number_of_relevant_repos != 0 else "n/a"  # TPR
            specificity = float(TN) / float(TN + FP) if (TN + FP) != 0 else "n/a"

            fpr = float(FP) / float(FP + TN) if float(FP + TN) != 0 else "n/a"

            fp_reduction = count_fp_reduction(sim[sim_index], gt, training)
            tp_reduction = count_fp_reduction(sim[sim_index], gt, training)
            fp_extension = count_fp_extension(sim[sim_index], gt, training)
            tp_extension = count_tp_extension(sim[sim_index], gt, training)

            evaluation_res[sim_index][pop_threshold] = {"pop":pop_threshold, "TP": TP, "FP": FP, "FN": FN, "TN":TN,
                                             "total_number_of_repos":total_number_of_repos,
                                             "precision":precision, "recall":recall,
                                             "sensitivity":sensitivity, "specificity":specificity,
                                             "fpr": fpr,
                                             "fp_reduction": fp_reduction, "tp_reduction": tp_reduction,
                                             "fp_extension": fp_extension, "tp_extension": tp_extension}

            print pop_threshold, ",", TP, ",", FP, ",", FN, ",", TN, \
                ",", total_number_of_repos, ",", precision, ",", recall, ",", sensitivity, ",", specificity, ",", fpr, \
                ",", fp_reduction, ",", tp_reduction, ",", fp_extension, ",", tp_extension

    if output_file_name is not None:
        with open(output_file_name + ".pickle", "w") as f_p:
            pickle.dump(evaluation_res, f_p)
            f_p.close()
        with open(output_file_name + ".json", "w") as f_p:
            f_p.write(str(evaluation_res))
            f_p.close()

        f_p = open(output_file_name + ".txt", "w")
        for sim_index, simulation in evaluation_res.iteritems():
            f_p.write("pop_threshold, TP, FP, FN, TN, total, precision, recall, sensitivity_tpr, specificity_tnr, fpr, fp_reduction, tp_reduction, fp_extension, tp_extension\n")
            for threshold, res,  in simulation.iteritems():
                f_p.write(str(res["pop"]))
                f_p.write(",")
                f_p.write(str(res["TP"]))
                f_p.write(",")
                f_p.write(str(res["FP"]))
                f_p.write(",")
                f_p.write(str(res["FN"]))
                f_p.write(",")
                f_p.write(str(res["TN"]))
                f_p.write(",")
                f_p.write(str(res["total_number_of_repos"]))
                f_p.write(",")
                f_p.write(str(res["precision"]))
                f_p.write(",")
                f_p.write(str(res["recall"]))
                f_p.write(",")
                f_p.write(str(res["sensitivity"]))
                f_p.write(",")
                f_p.write(str(res["specificity"]))
                f_p.write(",")
                f_p.write(str(res["fpr"]))
                f_p.write(",")
                f_p.write(str(res["fp_reduction"]))
                f_p.write(",")
                f_p.write(str(res["tp_reduction"]))
                f_p.write(",")
                f_p.write(str(res["fp_extension"]))
                f_p.write(",")
                f_p.write(str(res["tp_extension"]))
                f_p.write("\n")
        f_p.close()


if __name__ == "__main__":
    f_gt_pop = sys.argv[1]
    gt_pop = pickle.load(open(f_gt_pop, "r"))

    f_tr_pop = sys.argv[2]
    training_pop = pickle.load(open(f_tr_pop, "r"))

    simulation_pop = []
    number_of_simulations = len(sys.argv) - 3
    for i in range(3, len(sys.argv)):
        f_simulation_pop = sys.argv[i]
        simulation_pop.append(pickle.load(open(f_simulation_pop, "r")))

    evaluate_predictions(simulation_pop, gt_pop, training_pop, total_number_of_repos=3245042)
