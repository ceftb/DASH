#!/usr/bin/python
import sys
import datetime
import gzip
import json
from glob import glob


def file_date_range(date1,date2):
    start = datetime.datetime.strptime(date1, '%Y%m%d')
    end = datetime.datetime.strptime(date2, '%Y%m%d')
    step = datetime.timedelta(days=1)
    dates = []
    while start < end:
        dates.append(start.date().strftime('%Y%m%d'))
        start += step
    dates.append(start.date().strftime('%Y%m%d'))

    return dates


##### clean subtype
def replace_action(action):
    if action == 'opened' or action =='reopened':
        #act = action[:-2]
        act = action
    elif action == 'closed':
        #act = action[:-1]
        act = action
    else:
        act = ''
    return act


##### clean subtype
def replace_merge(a):
    if a == True:
        #b = 'merged'
        b = 'True'
    elif a == False:
        #b = 'not merged'
        b = 'False'
    else:
        b = ''
    return b


def event_process(d, d_omain):
    datapoint={}
    datapoint['domain'] = d_omain
    datapoint['nodeID'] = d['repo']['name_h']
    datapoint['nodeUserID'] = d['actor']['login_h']
    datapoint['actionType'] = d['type']
    #datapoint['nodeTime'] = d['created_at'].replace('T',' ').replace('Z','')
    datapoint['nodeTime'] = d['created_at']

    if d['type'] == "CreateEvent":
        datapoint['actionSubType'] = d['payload']['ref_type']
        datapoint['status'] = ''
        

    #elif d['type'] == 'DeleteEvent':
        #datapoint['actionSubType'] = d['payload']['ref_type']
        #datapoint['status'] = ''

    if d['type'] == 'IssuesEvent':
        datapoint['actionSubType'] = replace_action(d['payload']['action'])
        datapoint['status'] = ''

    elif d['type'] == 'PullRequestEvent':
        datapoint['actionSubType'] = replace_action(d['payload']['action'])
        datapoint['status'] = replace_merge(d['payload']['pull_request']['merged'])

    else:
        datapoint['actionSubType'] = ''
        datapoint['status'] = ''

    return datapoint
    



def github_to_json(p_in_event, p_in_repo, p_out, domain, min_date, max_date):

    """
    This file takes in Github Json files and outputs a submission JSON file.

    Inputs:
        p_in_event  : string : The location of Github event files to load. eg: '/home/rcf-proj/ef/palashgo/SocialSim/data/socialsim/events/'
        p_in_repo   : string : The location of Github repo files to load. eg: '/home/rcf-proj/ef/sapienza/2018DecCP/GitHub/'
        p_out       : string : The location to output the JSON file. eg: '/home/rcf-proj/ef/dh_599/github_chal/OUTput/script_out/'
        domain      : string : The domain this is simulating. Should be 'crypto', 'cyber', or 'CVE'.
        min_date    : string : min date. eg: '20170601'
        max_date    : string : max date. eg: '20170801'
       
    Output:
        JSON_file - saves a json file of the following form:
                {"team"     : 'usc',
                 "scenario" : 1,
                 "domain"   : domain,
                 "platform" : github,
                 "data":[
                 JSON_datapoint,
                 JSON_datapoint,
                 :
                 :
                 :
                 JSON_datapoint,
                 JSON_datapoint]
                 }
    """


    team_name = 'usc'
    scenario = 1
    platform = 'github'
    date_range = file_date_range(min_date,max_date)

    ## collect needed files
    if domain == 'crypto':
        f_repo = p_in_repo+'Crypto/crypto_related_repos.json'
        domain = 'cryptocurrency'
    elif domain == 'CVE':
        f_repo = glob(p_in_repo+'CVE/CVE_training/Srch_*.json.gz')
        domain = 'CVE'
    elif domain == 'cyber':
        f_repo = glob(p_in_repo+'Cyber/Cyber_training/Srch_*.json.gz')
        domain = 'Cybersecurity'
    else:
        domain = 'all'


    f_event =[]
    for i in date_range:
        f_event += glob(p_in_event+i[0:6]+'/'+i+'/an_*.json.gz')


    ## collect repo list
    repo_list = {}

    if domain == 'crypto':
        with open(f_repo, 'r') as f_in:
            for line in f_in:
                d = json.loads(line)
                repo_list[d['repo_name']] = d['extension']['socialsim_keywords']
    elif domain == 'all':
        repo_list = None
    else:
        for f_name in f_repo:
            with gzip.GzipFile(f_name,'r') as f_in:
                for line in f_in:
                    d= json.loads(line)
                    repo_list[d['repo_name']] = d['extension']['socialsim_keywords']

    ## parse event file
    f_out = open(p_out+'github_'+domain+'_'+min_date+'_'+max_date+'.json','w')
    f_out.write("{\"team\" : \"" + str(team_name) + "\", \"scenario\" : " + str(scenario) +
                ", \"domain\" : \"" + str(domain) + "\", \"platform\" : \"" + str(platform) + "\", \"data\" : " +
                "[")

    first_item = True
    event_counter = 0
    for f_eve in f_event:
        with gzip.GzipFile(f_eve,'r') as f_in:
            for line in f_in:
                d = json.loads(line)
                if (repo_list is None or d['repo']['name_h'] in repo_list) and ('name_h' in d['repo'] and 'login_h' in d['actor']):
                    d_out = event_process(d,domain)
                    if repo_list is not None:
                        d_out['keywords'] = repo_list[d['repo']['name_h']]
                    if not first_item:
                        f_out.write(", ")
                    first_item = False
                    json.dump(d_out, f_out)
                    event_counter += 1
                    if event_counter % 100000 == 0:
                        print "Processed event ", d['created_at']
    f_out.write("]}")
    f_out.close()
    return


if __name__=='__main__':
    github_to_json(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5], sys.argv[6])





